# 🧠 AI 8일차: 자연어처리 및 텍스트 파운데이션 모델 (거대 언어 모델)

---

## 📘 1. 텍스트 파운데이션 모델 살펴보기

### 1) 텍스트 파운데이션 모델 (거대 언어 모델)이란?
- **거대 언어 모델**(Large Language Models, LLMs)은 방대한 양의 **텍스트 데이터**를 기반으로 학습하여, **언어 이해**와 **생성**을 할 수 있는 모델입니다.
- **파운데이션 모델**은 다양한 자연어 처리(NLP) 작업에 **범용적으로 활용** 가능한 **기본 모델**로, 다양한 작업에 전이 학습을 통해 적용될 수 있습니다.

#### 🌐 예시:  
- GPT-3, GPT-4, BERT, T5, 등의 거대 언어 모델들이 있습니다. 이 모델들은 문맥을 이해하고, **자연스러운 텍스트 생성**과 **언어 추론**을 할 수 있습니다.

---

### 2) 거대 언어 모델 예시

#### 🔹 GPT-3 / GPT-4
- **GPT**(Generative Pretrained Transformer)는 **문맥 기반의 텍스트 생성**과 **자연어 이해**에 강점을 보이는 모델입니다.
- **GPT-3**는 1750억 개의 파라미터를 가지고 있으며, 텍스트를 **자유롭게 생성**하거나 주어진 **질문에 답변**하는 데 사용됩니다.
  
#### 🔹 BERT
- **BERT**(Bidirectional Encoder Representations from Transformers)는 **양방향** 텍스트 표현을 사용하여 **언어의 문맥적 의미**를 이해하는 데 뛰어난 성능을 보입니다.
  
#### 🔹 T5
- **T5**(Text-to-Text Transfer Transformer)는 **모든 NLP 문제를 텍스트-입력/텍스트-출력** 문제로 변환하여, 다양한 태스크에 사용할 수 있는 **범용 모델**입니다.

---

## 📗 2. 거대 언어 모델의 학습

### 1) 지시 학습 (Instruction-Based Learning)
- **지시 학습**은 모델에게 명확한 **지시문**을 주고, 그에 맞는 **출력**을 생성하도록 학습시키는 방법입니다.
- 예시: "이 문장을 긍정적인 표현으로 바꿔주세요", "이 기사에 대해 요약해 주세요."

#### 🔑 특징
- **학습 효율성**을 높이며, 모델이 다양한 작업을 수행할 수 있도록 훈련됩니다.

---

### 2) 선호 학습 (Preference-Based Learning)
- **선호 학습**은 모델이 **선택적 학습**을 통해 어떤 응답이 **선호되는지** 배우는 과정입니다.
- **응답 선택**에서 **자연어 처리**의 정확도를 높이기 위해, 훈련 데이터에서 사람들의 선호도를 반영합니다.

#### 🔑 특징
- 모델이 더 **정확하고 유용한** 출력을 생성하도록 유도합니다.

---

## ⚙️ 3. 거대 언어 모델의 추론

### 1) 디코딩 (Decoding)
- **디코딩**은 모델이 **출력 텍스트를 생성**하는 과정을 의미합니다. 주어진 **입력**에 대해 가능한 모든 출력을 **확률적으로 예측**합니다.
  
#### 🔹 디코딩 방식
- **Greedy Decoding**: 가장 높은 확률의 단어를 선택하여 출력
- **Beam Search**: 여러 후보를 동시에 고려하여 더 다양한 출력을 생성
- **Sampling**: 확률 분포를 기반으로 단어를 샘플링하여 다양한 결과를 도출

---

### 2) 프롬프트 엔지니어링 (Prompt Engineering)
- **프롬프트 엔지니어링**은 모델에 대한 **입력 질문**이나 지시를 **정교하게 설계**하는 기술입니다.
- 이를 통해 **모델의 성능**을 극대화하고, 원하는 출력을 유도할 수 있습니다.

#### 🔹 예시:
- "이 기사에서 중요한 정보는 무엇인가요?"
- "이 텍스트의 감정을 분석해 주세요."

프롬프트 설계의 **정확성**에 따라 모델의 **응답 품질**이 크게 달라질 수 있습니다.

---

## 📙 4. 거대 언어 모델의 평가와 응용

### 1) 거대 언어 모델의 평가
- **평가**는 모델이 생성한 텍스트가 얼마나 **자연스럽고** **정확한지**를 측정하는 과정입니다.
  
#### 🔹 평가 지표
- **BLEU (Bilingual Evaluation Understudy)**: 기계 번역 품질을 평가하는 지표
- **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: 텍스트 요약의 품질을 평가
- **Perplexity**: 모델의 **예측 능력**을 측정하는 지표

#### 🔹 평가 방법
- **모델 평가**는 **자동화된 테스트**나 **사용자 피드백**을 통해 이루어집니다.

---

### 2) 거대 언어 모델의 응용/한계

#### 🔹 응용
- **대화형 AI**: 챗봇, 가상 비서
- **문서 생성**: 뉴스, 보고서, 소설 등 다양한 텍스트 생성
- **자동 번역**: 다국어 텍스트 간의 번역
- **의료, 법률, 금융** 분야에서 **전문적 활용**

#### 🔹 한계
- **편향성**: 훈련 데이터에 있는 **편향된 정보**를 모델이 학습할 수 있음
- **불확실성**: 모델이 항상 **정확한 정보**를 생성하지 않음
- **높은 계산 자원**: 대규모 모델은 **막대한 계산 자원**과 **시간**을 소모

---

## 📚 요약

| 구분 | 주요 개념 | 핵심 포인트 |
|------|------------|-------------|
| 텍스트 파운데이션 모델 | 거대 언어 모델 (LLMs) | 다양한 텍스트 작업을 위한 기본 모델 |
| 지시 학습 | Instruction-Based Learning | 모델에게 명확한 지시를 주어 훈련 |
| 선호 학습 | Preference-Based Learning | 모델의 응답 품질을 사람의 선호로 향상 |
| 디코딩 | 모델의 텍스트 생성 방식 | 다양한 디코딩 기법을 통한 텍스트 생성 |
| 프롬프트 엔지니어링 | 입력 지시 설계 | 모델의 성능 향상을 위한 프롬프트 최적화 |

---

> 💡 **Tip:**  
> **프롬프트 엔지니어링**은 거대 언어 모델을 효율적으로 활용하기 위한 **핵심 기술**입니다. 다양한 방식으로 모델을 조정하여 더 나은 출력을 얻을 수 있습니다.
